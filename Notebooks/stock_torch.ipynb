{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:29:05.850312900Z",
     "start_time": "2025-03-08T23:29:05.842430400Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.metrics.metrics import mae, rmse, mape, smape\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torcheval.metrics.functional import binary_accuracy, binary_f1_score, binary_precision, binary_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "def evaluate_regression_metrics(actual, pred):\n",
    "    actual = TimeSeries.from_series(pd.DataFrame(actual).squeeze())\n",
    "    pred = TimeSeries.from_series(pd.DataFrame(pred).squeeze())\n",
    "    result = {}\n",
    "    result[\"MAE\"] = mae(actual, pred)\n",
    "    result[\"RMSE\"] = rmse(actual, pred)\n",
    "    result[\"MAPE\"] = mape(actual, pred)\n",
    "    result[\"SMAPE\"] = smape(actual, pred)\n",
    "    return result\n",
    "\n",
    "def evaluate_classification_metrics(actual, pred, threshold=0.5):\n",
    "    actual = actual.squeeze()\n",
    "    pred = pred.squeeze()\n",
    "    pred = (pred >= threshold).int()\n",
    "\n",
    "    result = {}\n",
    "    result[\"Accuracy\"] = binary_accuracy(actual, pred)\n",
    "    result[\"F1\"] = binary_f1_score(actual, pred)\n",
    "    result[\"Precision\"] = binary_precision(actual, pred)\n",
    "    result[\"Recall\"] = binary_recall(actual, pred)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:31:19.508760500Z",
     "start_time": "2025-03-08T23:31:19.503040400Z"
    }
   },
   "id": "3afd59215c46b0c3"
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "def evaluate_test(model, test_loader, device, loss_fn, calculate_metrics):\n",
    "    model.eval()\n",
    "    outputs_list = []\n",
    "    labels_list = []\n",
    "    test_loss = 0\n",
    "    inputs, labels = next(iter(test_loader))\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        outputs_list.append(outputs.cpu())\n",
    "        labels_list.append(labels.cpu())\n",
    "        \n",
    "    outputs_concat = torch.cat(outputs_list, dim=0)\n",
    "    labels_concat = torch.cat(labels_list, dim=0)\n",
    "    \n",
    "    metrics = calculate_metrics(labels_concat, outputs_concat)\n",
    "    print(f'Test Loss: {test_loss}')\n",
    "    print(f'Test Metrics, {metrics}')\n",
    "    \n",
    "    wandb.log({\n",
    "        'test_loss': test_loss,\n",
    "        'test_metrics': metrics,\n",
    "    })\n",
    "    \n",
    "    return test_loss, metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:31:19.709423300Z",
     "start_time": "2025-03-08T23:31:19.704562400Z"
    }
   },
   "id": "8ad4004ac0fa7b6c"
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, n_past, n_predict, n_stride=1, classification=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: Input time series data.\n",
    "            n_past: Number of past time steps as input.\n",
    "            n_predict: Number of future time steps to predict.\n",
    "            n_stride: Step size for moving window.\n",
    "            classification: If True, convert future values into classification labels (higher/lower).\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.n_past = n_past\n",
    "        self.n_predict = n_predict\n",
    "        self.n_stride = n_stride\n",
    "        self.classification = classification\n",
    "        self.samples = self._create_samples()\n",
    "    \n",
    "    def _create_samples(self):\n",
    "        samples = []\n",
    "        for i in range(0, len(self.data) - self.n_past - self.n_predict + 1, self.n_stride):\n",
    "            past = self.data[i : i + self.n_past]\n",
    "            future = self.data[i + self.n_past : i + self.n_past + self.n_predict]\n",
    "            \n",
    "            if self.classification:\n",
    "                # Generate classification labels for all future steps\n",
    "                labels = [1 if future[j] > past[-1] else 0 for j in range(len(future))]\n",
    "                samples.append((past, labels))\n",
    "            else:\n",
    "                samples.append((past, future))\n",
    "        return samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        past, target = self.samples[idx]\n",
    "        return (torch.tensor(past.squeeze(-1), dtype=torch.float32), \n",
    "                torch.tensor(target, dtype=torch.long \n",
    "                if self.classification else torch.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:31:20.159875300Z",
     "start_time": "2025-03-08T23:31:20.155851Z"
    }
   },
   "id": "19e71f8494ae3788"
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, device, optimizer, loss_fn, train_loader, val_loader, n_epochs,\n",
    "                 calculate_metrics, run_name, patience=10):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.calculate_metrics = calculate_metrics\n",
    "        self.n_epochs = n_epochs\n",
    "        self.patience = patience\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.patience_counter = 0\n",
    "        self.best_model_state = None\n",
    "        self.early_stopped = False\n",
    "        self.run_name = run_name\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        for epoch in range(self.n_epochs):\n",
    "            train_loss = self._train_epoch(epoch)\n",
    "            val_loss, metrics = self._val_epoch(epoch)\n",
    "            wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "            wandb.log(metrics)\n",
    "            self._early_stopping(val_loss)\n",
    "            if self.early_stopped:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "            \n",
    "        print(\"Training complete, saving best and final model.\")\n",
    "        self._save_best_model()\n",
    "        self._save_final_model()\n",
    "        \n",
    "        best_model = copy.deepcopy(self.model)  \n",
    "        best_model.load_state_dict(self.best_model_state)\n",
    "        return best_model \n",
    "            \n",
    "    def _train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        train_loss = 0\n",
    "        for batch in self.train_loader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.loss_fn(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss / len(self.train_loader)}')\n",
    "        return train_loss / len(self.train_loader)\n",
    "    \n",
    "    def _val_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        outputs_list = []\n",
    "        labels_list = []\n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                inputs, labels = batch\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss_fn(outputs, labels.float())\n",
    "                val_loss += loss.item()\n",
    "                outputs_list.append(outputs.cpu())\n",
    "                labels_list.append(labels.cpu())\n",
    "                \n",
    "        outputs_concat = torch.cat(outputs_list, dim=0)\n",
    "        labels_concat = torch.cat(labels_list, dim=0)\n",
    "        \n",
    "        metrics = self.calculate_metrics(labels_concat, outputs_concat)\n",
    "        print(f'Epoch {epoch+1}, Validation Loss: {val_loss / len(self.val_loader)}')\n",
    "        print(f\"Metrics\", metrics)\n",
    "        return val_loss / len(self.val_loader), metrics\n",
    "    \n",
    "    def _early_stopping(self, val_loss):\n",
    "        if val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.patience_counter = 0\n",
    "            self.best_model_state = self.model.state_dict()\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "            if self.patience_counter >= self.patience:\n",
    "                self.early_stopped = True\n",
    "                \n",
    "                \n",
    "    def _save_best_model(self):\n",
    "        if self.best_model_state is not None:\n",
    "            torch.save(self.best_model_state, f\"../artifacts/{self.run_name}_best_model.pth\")\n",
    "            artifact = wandb.Artifact(f\"{self.run_name}_best_model\", type=\"model\")\n",
    "            artifact.add_file(f\"../artifacts/{self.run_name}_best_model.pth\")\n",
    "            wandb.log_artifact(artifact)\n",
    "            print(\"Best model saved to WandB.\")\n",
    "\n",
    "    def _save_final_model(self):\n",
    "        torch.save(self.model.state_dict(), f\"../artifacts/{self.run_name}_final_model.pth\")\n",
    "        artifact = wandb.Artifact(f\"{self.run_name}_final_model\", type=\"model\")\n",
    "        artifact.add_file(f\"../artifacts/{self.run_name}_final_model.pth\")\n",
    "        wandb.log_artifact(artifact)\n",
    "        print(\"Final model saved to WandB.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:31:20.347037200Z",
     "start_time": "2025-03-08T23:31:20.331637900Z"
    }
   },
   "id": "b64ea4198faf2fc7"
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, n_past, n_predict):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(n_past, n_predict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:31:20.573305100Z",
     "start_time": "2025-03-08T23:31:20.566284800Z"
    }
   },
   "id": "a70fcfaa0c56422"
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [],
   "source": [
    "class LinearLayerClassification(nn.Module):\n",
    "    def __init__(self, n_past, n_predict):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_past, 10)\n",
    "        self.fc2 = nn.Linear(10, 4)\n",
    "        self.fc3 = nn.Linear(4, n_predict)\n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.sigmoid(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:31:20.844651500Z",
     "start_time": "2025-03-08T23:31:20.838564300Z"
    }
   },
   "id": "385ae1e80c6639e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, n_past, n_predict):\n",
    "        super().__init__()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8213665b2cbe3d0"
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    wandb.init(dir=\"../wandb\", project=\"stock_time_series\", name=config[\"run_name\"], config=config)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"using {device}\")\n",
    "    is_classification = config[\"is_classification\"]\n",
    "    \n",
    "    \n",
    "    df_train = pd.read_csv(\"../data/train.csv\", parse_dates=[\"timestamp\"])[\"low\"]\n",
    "    df_val = pd.read_csv(\"../data/validate.csv\", parse_dates=[\"timestamp\"])[\"low\"]\n",
    "    df_test = pd.read_csv(\"../data/test.csv\", parse_dates=[\"timestamp\"])[\"low\"]\n",
    "    \n",
    "    scaler_transformer = None\n",
    "    if config[\"scaler\"] == \"min-max\":\n",
    "        scaler_transformer = MinMaxScaler()\n",
    "    elif config[\"scaler\"] == \"std\":\n",
    "        scaler_transformer = StandardScaler()\n",
    "        \n",
    "    train_series = scaler_transformer.fit_transform(df_train.to_frame())\n",
    "    val_series = scaler_transformer.transform(df_val.to_frame())\n",
    "    test_series = scaler_transformer.transform(df_test.to_frame())\n",
    "    \n",
    "    train_dataset  = TimeSeriesDataset(train_series, \n",
    "                                       n_past=config[\"n_past\"], \n",
    "                                       n_predict=config[\"n_predict\"], \n",
    "                                       n_stride=config[\"n_stride\"],\n",
    "                                       classification=is_classification)\n",
    "    val_dataset  = TimeSeriesDataset(val_series, \n",
    "                                   n_past=config[\"n_past\"], \n",
    "                                   n_predict=config[\"n_predict\"], \n",
    "                                   n_stride=config[\"n_stride\"],\n",
    "                                   classification=is_classification)\n",
    "    test_dataset  = TimeSeriesDataset(test_series, \n",
    "                                   n_past=config[\"n_past\"], \n",
    "                                   n_predict=config[\"n_predict\"], \n",
    "                                   n_stride=config[\"n_stride\"],\n",
    "                                   classification=is_classification)\n",
    "    \n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    \n",
    "\n",
    "    if is_classification:\n",
    "        model = LinearLayerClassification(n_past=config[\"n_past\"], n_predict=config[\"n_predict\"])\n",
    "        loss_fn = nn.BCELoss()\n",
    "        calculate_metrics = partial(evaluate_classification_metrics, threshold=config[\"threshold\"])\n",
    "    else:\n",
    "        model = LinearLayer(n_past=config[\"n_past\"], n_predict=config[\"n_predict\"])\n",
    "        loss_fn = nn.MSELoss()\n",
    "        calculate_metrics = evaluate_regression_metrics\n",
    "        \n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    \n",
    "    trainer = Trainer(model = model, \n",
    "                      device = device, \n",
    "                      optimizer = optimizer,\n",
    "                      loss_fn = loss_fn,\n",
    "                      train_loader = train_dataloader,\n",
    "                      val_loader = val_dataloader,\n",
    "                      calculate_metrics = calculate_metrics,\n",
    "                      n_epochs = config[\"n_epochs\"],\n",
    "                      run_name = config[\"run_name\"],\n",
    "                      patience=10)\n",
    "    trainer.train()\n",
    "    \n",
    "    evaluate_test(model, test_dataloader, device, loss_fn, calculate_metrics=calculate_metrics)\n",
    "    wandb.finish()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:31:21.107862600Z",
     "start_time": "2025-03-08T23:31:21.104817400Z"
    }
   },
   "id": "50738fc8b13787f3"
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    return {\n",
    "        \"is_classification\" : True,\n",
    "        \"run_name\" : \"classification-test\",\n",
    "        \n",
    "        \"scaler\" : \"min-max\",\n",
    "        \"batch_size\" : 16,\n",
    "        \"threshold\" : 0.5,\n",
    "        \n",
    "        \"n_past\" : 20,\n",
    "        \"n_predict\" : 1,\n",
    "        \"n_stride\" : 1,\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"n_epochs\" : 5,\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:31:21.323232600Z",
     "start_time": "2025-03-08T23:31:21.316829600Z"
    }
   },
   "id": "adcb1e2cfebbffe0"
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.19.8"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>../wandb\\wandb\\run-20250308_183121-ikx7vsuj</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/aafvbd/stock_time_series/runs/ikx7vsuj' target=\"_blank\">classification-test</a></strong> to <a href='https://wandb.ai/aafvbd/stock_time_series' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/aafvbd/stock_time_series' target=\"_blank\">https://wandb.ai/aafvbd/stock_time_series</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/aafvbd/stock_time_series/runs/ikx7vsuj' target=\"_blank\">https://wandb.ai/aafvbd/stock_time_series/runs/ikx7vsuj</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n",
      "Epoch 1, Train Loss: 0.6947396462578928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
      "WARNING:root:No positive instances have been seen in target. Recall is converted from NaN to 0s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.6991743456411655\n",
      "Metrics {'Accuracy': tensor(0.4886), 'F1': tensor(0.), 'Precision': tensor(0.), 'Recall': tensor(0.)}\n",
      "Epoch 2, Train Loss: 0.6937140119075775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
      "WARNING:root:No positive instances have been seen in target. Recall is converted from NaN to 0s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Loss: 0.6966246834036262\n",
      "Metrics {'Accuracy': tensor(0.4886), 'F1': tensor(0.), 'Precision': tensor(0.), 'Recall': tensor(0.)}\n",
      "Epoch 3, Train Loss: 0.693503985135786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
      "WARNING:root:No positive instances have been seen in target. Recall is converted from NaN to 0s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Loss: 0.6955371250606905\n",
      "Metrics {'Accuracy': tensor(0.4886), 'F1': tensor(0.), 'Precision': tensor(0.), 'Recall': tensor(0.)}\n",
      "Epoch 4, Train Loss: 0.6933967449972707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
      "WARNING:root:No positive instances have been seen in target. Recall is converted from NaN to 0s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Loss: 0.6949830033206352\n",
      "Metrics {'Accuracy': tensor(0.4886), 'F1': tensor(0.), 'Precision': tensor(0.), 'Recall': tensor(0.)}\n",
      "Epoch 5, Train Loss: 0.6933339217016774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
      "WARNING:root:No positive instances have been seen in target. Recall is converted from NaN to 0s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Loss: 0.6946813187560017\n",
      "Metrics {'Accuracy': tensor(0.4886), 'F1': tensor(0.), 'Precision': tensor(0.), 'Recall': tensor(0.)}\n",
      "Training complete, saving best and final model.\n",
      "Best model saved to WandB.\n",
      "Final model saved to WandB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
      "WARNING:root:No positive instances have been seen in target. Recall is converted from NaN to 0s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6957568526268005\n",
      "Test Metrics, {'Accuracy': tensor(0.4919), 'F1': tensor(0.), 'Precision': tensor(0.), 'Recall': tensor(0.)}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▁▁▁▁</td></tr><tr><td>F1</td><td>▁▁▁▁▁</td></tr><tr><td>Precision</td><td>▁▁▁▁▁</td></tr><tr><td>Recall</td><td>▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>val_loss</td><td>█▄▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.48856</td></tr><tr><td>F1</td><td>0</td></tr><tr><td>Precision</td><td>0</td></tr><tr><td>Recall</td><td>0</td></tr><tr><td>test_loss</td><td>0.69576</td></tr><tr><td>train_loss</td><td>0.69333</td></tr><tr><td>val_loss</td><td>0.69468</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">classification-test</strong> at: <a href='https://wandb.ai/aafvbd/stock_time_series/runs/ikx7vsuj' target=\"_blank\">https://wandb.ai/aafvbd/stock_time_series/runs/ikx7vsuj</a><br> View project at: <a href='https://wandb.ai/aafvbd/stock_time_series' target=\"_blank\">https://wandb.ai/aafvbd/stock_time_series</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>../wandb\\wandb\\run-20250308_183121-ikx7vsuj\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    seed = 42\n",
    "    random.seed(42)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    config = get_config()\n",
    "    main(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:31:34.675675100Z",
     "start_time": "2025-03-08T23:31:21.603723100Z"
    }
   },
   "id": "2bda7478aa551d7c"
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T22:46:46.038442600Z",
     "start_time": "2025-03-08T22:46:46.034858700Z"
    }
   },
   "id": "a91aad98faa683eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "29cad13e51ea7e52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
