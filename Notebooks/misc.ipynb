{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, num_samples=20, seq_length=20, pattern_strength=1.0):\n",
    "        \"\"\"\n",
    "        Create a simple dataset where the class is determined by a pattern in the sequence.\n",
    "        Higher pattern_strength makes the pattern more obvious (easier to learn).\n",
    "        \"\"\"\n",
    "        self.seq_length = seq_length\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Generate a random sequence\n",
    "            seq = np.random.randn(seq_length)\n",
    "            \n",
    "            # Create a pattern: if the first value is positive, class = 1, else 0\n",
    "            # Add some additional signal in the first few elements to make it stronger\n",
    "            if random.random() > 0.5:\n",
    "                # Class 1 pattern\n",
    "                seq[0] += pattern_strength * 2  # Make first value likely positive\n",
    "                label = 1\n",
    "            else:\n",
    "                # Class 0 pattern\n",
    "                seq[0] -= pattern_strength * 2  # Make first value likely negative\n",
    "                label = 0\n",
    "                \n",
    "            self.data.append(seq)\n",
    "            self.labels.append(label)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.data[idx]), torch.tensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# class RNNEncoderClassifier(nn.Module):\n",
    "#     def __init__(self, n_predict, n_features, n_hidden, n_layers, dropout):\n",
    "#         super().__init__()\n",
    "#         self.rnn = nn.RNN(input_size=n_features,\n",
    "#                           hidden_size=n_hidden,\n",
    "#                           num_layers=n_layers,\n",
    "#                           nonlinearity=\"relu\",\n",
    "#                           dropout=dropout,\n",
    "#                           bidirectional=False,\n",
    "#                           batch_first=True)\n",
    "#         self.fc = nn.Linear(n_hidden, n_predict)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#         \n",
    "#     def forward(self, x):\n",
    "#         # Make sure x has the right shape [batch, seq_len, features]\n",
    "#         if x.dim() == 2:\n",
    "#             x = x.unsqueeze(-1)\n",
    "#         \n",
    "#         output, hn = self.rnn(x)\n",
    "#         x = self.fc(hn[-1])\n",
    "#         return self.sigmoid(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f13862bb60ec37b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main2(config, use_wandb=False):\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize wandb if needed\n",
    "    if use_wandb:\n",
    "        try:\n",
    "            wandb.init(project=\"model-debugging\", \n",
    "                       name=config[\"run_name\"],\n",
    "                       config=config)\n",
    "        except:\n",
    "            print(\"WandB initialization skipped\")\n",
    "            use_wandb = False\n",
    "    \n",
    "    # Create tiny dataset for overfitting test\n",
    "    train_dataset = SimpleDataset(num_samples=200, seq_length=config[\"n_past\"], pattern_strength=2.0)\n",
    "    val_dataset = SimpleDataset(num_samples=50, seq_length=config[\"n_past\"], pattern_strength=2.0)\n",
    "    test_dataset = SimpleDataset(num_samples=50, seq_length=config[\"n_past\"], pattern_strength=2.0)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    # Create model\n",
    "    model = RNNEncoderClassifier(n_predict=config[\"n_predict\"],\n",
    "                                n_features=config[\"n_features\"],\n",
    "                                n_hidden=config[\"n_hidden\"],\n",
    "                                n_layers=config[\"n_layers\"],\n",
    "                                dropout=config[\"dropout\"])\n",
    "    \n",
    "    \n",
    "    # Set up loss function and metrics\n",
    "    loss_fn = nn.BCELoss()\n",
    "    calculate_metrics = partial(evaluate_classification_metrics, threshold=config[\"threshold\"])\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(model=model,\n",
    "                     device=device,\n",
    "                     optimizer=optimizer,\n",
    "                     loss_fn=loss_fn,\n",
    "                     train_loader=train_dataloader,\n",
    "                     val_loader=val_dataloader,\n",
    "                     calculate_metrics=calculate_metrics,\n",
    "                     n_epochs=config[\"n_epochs\"],\n",
    "                     run_name=config[\"run_name\"],\n",
    "                     patience=config[\"patience\"])\n",
    "    \n",
    "    # Train model\n",
    "    best_model = trainer.train()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    evaluate_test(best_model, test_dataloader, device, loss_fn, calculate_metrics)\n",
    "    \n",
    "    if use_wandb:\n",
    "        try:\n",
    "            wandb.finish()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return best_model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3e83f663c3672cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    return {\n",
    "        \"run_name\": \"rnn_encoder_overfit_test\",\n",
    "        \"notes\": \"Testing overfitting capability with tiny dataset\",\n",
    "        \n",
    "        \"is_classification\": True,\n",
    "        \"n_features\": 1,\n",
    "        \"n_past\": 20,\n",
    "        \"n_predict\": 1,\n",
    "        \"n_stride\": 1,\n",
    "        \n",
    "        \"model\": \"rnn_encoder\",\n",
    "        \"n_hidden\": 32,\n",
    "        \"n_layers\": 2,\n",
    "        \"dropout\": 0.0,  # Set to 0 for overfitting test\n",
    "        \n",
    "        \"n_epochs\": 200,  # Increase epochs to allow for overfitting\n",
    "        \"batch_size\": 15,  # Small batch size for overfitting\n",
    "        \"threshold\": 0.5,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"patience\": 50,  # Increase patience for overfitting test\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dea0e9b05f91ff9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set seeds for reproducibility\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # Get configuration\n",
    "    config = get_config()\n",
    "    \n",
    "    # Run with or without wandb\n",
    "    use_wandb = True  # Set to False to skip wandb logging\n",
    "    main2(config, use_wandb)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51f5b8978c312804"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
