{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:35:05.398479900Z",
     "start_time": "2025-03-08T09:35:05.196651700Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.datasets import SunspotsDataset\n",
    "from darts.metrics.metrics import mae, rmse, mape, smape\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torcheval.metrics.functional import binary_accuracy, binary_f1_score, binary_precision, binary_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [],
   "source": [
    "def evaluate_regression_metrics(actual, pred):\n",
    "    actual = TimeSeries.from_series(pd.DataFrame(actual).squeeze())\n",
    "    pred = TimeSeries.from_series(pd.DataFrame(pred).squeeze())\n",
    "    result = {}\n",
    "    result[\"MAE\"] = mae(actual, pred)\n",
    "    result[\"RMSE\"] = rmse(actual, pred)\n",
    "    result[\"MAPE\"] = mape(actual, pred)\n",
    "    result[\"SMAPE\"] = smape(actual, pred)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:35:05.493287700Z",
     "start_time": "2025-03-08T09:35:05.401480500Z"
    }
   },
   "id": "b868bd15d518ae00"
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [],
   "source": [
    "def evaluate_classification_metrics(actual, pred):\n",
    "    actual = actual.squeeze()\n",
    "    pred = pred.squeeze()\n",
    "    result = {}\n",
    "    result[\"Accuracy\"] = binary_accuracy(actual, pred)\n",
    "    result[\"F1\"] = binary_f1_score(actual, pred)\n",
    "    result[\"Precision\"] = binary_precision(actual, pred)\n",
    "    result[\"Recall\"] = binary_recall(actual, pred)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:35:05.644312600Z",
     "start_time": "2025-03-08T09:35:05.546739800Z"
    }
   },
   "id": "f727b849b2f239d9"
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [],
   "source": [
    "def evaluate_test(model, test_loader, device, loss_fn, calculate_metrics):\n",
    "    model.eval()\n",
    "    outputs_list = []\n",
    "    labels_list = []\n",
    "    test_loss = 0\n",
    "    inputs, labels = next(iter(test_loader))\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        outputs_list.append(outputs.cpu())\n",
    "        labels_list.append(labels.cpu())\n",
    "        \n",
    "    outputs_concat = torch.cat(outputs_list, dim=0)\n",
    "    labels_concat = torch.cat(labels_list, dim=0)\n",
    "    \n",
    "    metrics = calculate_metrics(outputs_concat, labels_concat)\n",
    "    print(f'Test Loss: {test_loss}')\n",
    "    print(f'Test Metrics, {metrics}')\n",
    "    \n",
    "    wandb.log({\n",
    "        'test_loss': test_loss,\n",
    "        'test_metrics': metrics,\n",
    "    })\n",
    "    \n",
    "    return test_loss, metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:35:05.850407800Z",
     "start_time": "2025-03-08T09:35:05.755911700Z"
    }
   },
   "id": "c354430cc82f82ee"
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, n_past, n_predict, n_stride=1, classification=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: Input time series data.\n",
    "            n_past: Number of past time steps as input.\n",
    "            n_predict: Number of future time steps to predict.\n",
    "            n_stride: Step size for moving window.\n",
    "            classification: If True, convert future values into classification labels (higher/lower).\n",
    "        \"\"\"\n",
    "        self.data = data.pd_series().values  # Convert to Pandas Series and extract values\n",
    "        self.n_past = n_past\n",
    "        self.n_predict = n_predict\n",
    "        self.n_stride = n_stride\n",
    "        self.classification = classification\n",
    "        self.samples = self._create_samples()\n",
    "    \n",
    "    def _create_samples(self):\n",
    "        samples = []\n",
    "        for i in range(0, len(self.data) - self.n_past - self.n_predict + 1, self.n_stride):\n",
    "            past = self.data[i : i + self.n_past]\n",
    "            future = self.data[i + self.n_past : i + self.n_past + self.n_predict]\n",
    "            \n",
    "            if self.classification:\n",
    "                # Generate classification labels for all future steps\n",
    "                labels = [1 if future[j] > past[-1] else 0 for j in range(len(future))]\n",
    "                samples.append((past, labels))\n",
    "            else:\n",
    "                samples.append((past, future))\n",
    "        return samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        past, target = self.samples[idx]\n",
    "        return torch.tensor(past, dtype=torch.float32), torch.tensor(target, dtype=torch.long if self.classification else torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:35:06.067904800Z",
     "start_time": "2025-03-08T09:35:05.972222500Z"
    }
   },
   "id": "6b7043803d717bc0"
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, n_past, n_predict):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(n_past, n_predict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:35:06.249504600Z",
     "start_time": "2025-03-08T09:35:06.154157400Z"
    }
   },
   "id": "a157fdf17b7c36f"
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [],
   "source": [
    "class LinearLayerClassification(nn.Module):\n",
    "    def __init__(self, n_past, n_predict):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(n_past, n_predict)\n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return self.sigmoid(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:35:06.894424400Z",
     "start_time": "2025-03-08T09:35:06.799847900Z"
    }
   },
   "id": "4aca98cbd06d8b90"
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, device, optimizer, loss_fn, train_loader, val_loader, n_epochs,\n",
    "                 calculate_metrics, run_name, patience=10):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.calculate_metrics = calculate_metrics\n",
    "        self.n_epochs = n_epochs\n",
    "        self.patience = patience\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.patience_counter = 0\n",
    "        self.best_model_state = None\n",
    "        self.early_stopped = False\n",
    "        self.run_name = run_name\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        for epoch in range(self.n_epochs):\n",
    "            train_loss = self._train_epoch(epoch)\n",
    "            val_loss, metrics = self._val_epoch(epoch)\n",
    "            wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "            wandb.log(metrics)\n",
    "            self._early_stopping(val_loss)\n",
    "            if self.early_stopped:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "            \n",
    "        print(\"Training complete, saving best and final model.\")\n",
    "        self._save_best_model()\n",
    "        self._save_final_model()\n",
    "        \n",
    "        best_model = copy.deepcopy(self.model)  \n",
    "        best_model.load_state_dict(self.best_model_state)\n",
    "        return best_model \n",
    "            \n",
    "    def _train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        train_loss = 0\n",
    "        for batch in self.train_loader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            # print(outputs)\n",
    "            # print(labels)\n",
    "            loss = self.loss_fn(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss / len(self.train_loader)}')\n",
    "        return train_loss / len(self.train_loader)\n",
    "    \n",
    "    def _val_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        outputs_list = []\n",
    "        labels_list = []\n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                inputs, labels = batch\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss_fn(outputs, labels.float())\n",
    "                val_loss += loss.item()\n",
    "                outputs_list.append(outputs.cpu())\n",
    "                labels_list.append(labels.cpu())\n",
    "                \n",
    "        outputs_concat = torch.cat(outputs_list, dim=0)\n",
    "        labels_concat = torch.cat(labels_list, dim=0)\n",
    "        metrics = self.calculate_metrics(outputs_concat, labels_concat)\n",
    "        print(f'Epoch {epoch+1}, Validation Loss: {val_loss / len(self.val_loader)}')\n",
    "        print(f\"Metrics\", metrics)\n",
    "        return val_loss / len(self.val_loader), metrics\n",
    "    \n",
    "    def _early_stopping(self, val_loss):\n",
    "        if val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.patience_counter = 0\n",
    "            self.best_model_state = self.model.state_dict()\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "            if self.patience_counter >= self.patience:\n",
    "                self.early_stopped = True\n",
    "                \n",
    "                \n",
    "    def _save_best_model(self):\n",
    "        if self.best_model_state is not None:\n",
    "            torch.save(self.best_model_state, f\"../artifacts/{self.run_name}_best_model.pth\")\n",
    "            artifact = wandb.Artifact(f\"{self.run_name}_best_model\", type=\"model\")\n",
    "            artifact.add_file(f\"../artifacts/{self.run_name}_best_model.pth\")\n",
    "            wandb.log_artifact(artifact)\n",
    "            print(\"Best model saved to WandB.\")\n",
    "\n",
    "    def _save_final_model(self):\n",
    "        torch.save(self.model.state_dict(), f\"../artifacts/{self.run_name}_final_model.pth\")\n",
    "        artifact = wandb.Artifact(f\"{self.run_name}_final_model\", type=\"model\")\n",
    "        artifact.add_file(f\"../artifacts/{self.run_name}_final_model.pth\")\n",
    "        wandb.log_artifact(artifact)\n",
    "        print(\"Final model saved to WandB.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:35:07.135393300Z",
     "start_time": "2025-03-08T09:35:07.041164300Z"
    }
   },
   "id": "be2f55e358902838"
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    wandb.init(dir=\"../wandb\", project=\"toy_time_series\", name=config[\"run_name\"], config=config)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"using {device}\")\n",
    "    is_classification = config[\"is_classification\"]\n",
    "    \n",
    "    \n",
    "    full_series = SunspotsDataset().load()\n",
    "    train, val_test = full_series.split_after(0.80)\n",
    "    val, test = val_test.split_after(0.50)\n",
    "    scaler_transformer = Scaler()\n",
    "    train_series = scaler_transformer.fit_transform(train)\n",
    "    val_series = scaler_transformer.transform(val)\n",
    "    test_series = scaler_transformer.transform(test)\n",
    "    \n",
    "    train_dataset  = TimeSeriesDataset(train_series, \n",
    "                                       n_past=config[\"n_past\"], \n",
    "                                       n_predict=config[\"n_predict\"], \n",
    "                                       n_stride=config[\"n_stride\"],\n",
    "                                       classification=is_classification)\n",
    "    val_dataset  = TimeSeriesDataset(val_series, \n",
    "                                   n_past=config[\"n_past\"], \n",
    "                                   n_predict=config[\"n_predict\"], \n",
    "                                   n_stride=config[\"n_stride\"],\n",
    "                                   classification=is_classification)\n",
    "    test_dataset  = TimeSeriesDataset(test_series, \n",
    "                                   n_past=config[\"n_past\"], \n",
    "                                   n_predict=config[\"n_predict\"], \n",
    "                                   n_stride=config[\"n_stride\"],\n",
    "                                   classification=is_classification)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    \n",
    "\n",
    "    if is_classification:\n",
    "        model = LinearLayerClassification(n_past=config[\"n_past\"], n_predict=config[\"n_predict\"])\n",
    "        loss_fn = nn.BCELoss()\n",
    "        calculate_metrics = evaluate_classification_metrics\n",
    "    else:\n",
    "        model = LinearLayer(n_past=config[\"n_past\"], n_predict=config[\"n_predict\"])\n",
    "        loss_fn = nn.MSELoss()\n",
    "        calculate_metrics = evaluate_regression_metrics\n",
    "        \n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    \n",
    "    trainer = Trainer(model = model, \n",
    "                      device = device, \n",
    "                      optimizer = optimizer,\n",
    "                      loss_fn = loss_fn,\n",
    "                      train_loader = train_dataloader,\n",
    "                      val_loader = val_dataloader,\n",
    "                      calculate_metrics = calculate_metrics,\n",
    "                      n_epochs = config[\"n_epochs\"],\n",
    "                      run_name = config[\"run_name\"],\n",
    "                      patience=10)\n",
    "    trainer.train()\n",
    "    \n",
    "    evaluate_test(model, test_dataloader, device, loss_fn, calculate_metrics=calculate_metrics)\n",
    "    wandb.finish()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:36:26.835549300Z",
     "start_time": "2025-03-08T09:36:26.741759700Z"
    }
   },
   "id": "98cde4bc11ea07dd"
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    return {\n",
    "        \"is_classification\" : False,\n",
    "        \"run_name\" : \"RegressionTOY\",\n",
    "        \"n_past\" : 10,\n",
    "        \"n_predict\" : 1,\n",
    "        \"n_stride\" : 1,\n",
    "        \"batch_size\" : 16,\n",
    "        \"n_epochs\" : 50,\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:36:59.947190800Z",
     "start_time": "2025-03-08T09:36:59.856135400Z"
    }
   },
   "id": "f33f266262f1ddb8"
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.19.8"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>../wandb\\wandb\\run-20250308_043701-ith7iwh9</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/aafvbd/toy_time_series/runs/ith7iwh9' target=\"_blank\">RegressionTOY</a></strong> to <a href='https://wandb.ai/aafvbd/toy_time_series' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/aafvbd/toy_time_series' target=\"_blank\">https://wandb.ai/aafvbd/toy_time_series</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/aafvbd/toy_time_series/runs/ith7iwh9' target=\"_blank\">https://wandb.ai/aafvbd/toy_time_series/runs/ith7iwh9</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n",
      "Epoch 1, Train Loss: 0.030280823105985812\n",
      "Epoch 1, Validation Loss: 0.05056411520961453\n",
      "Metrics {'MAE': 0.180115, 'RMSE': 0.22486466, 'MAPE': 66.65199, 'SMAPE': 64.78689}\n",
      "Epoch 2, Train Loss: 0.01739121761820312\n",
      "Epoch 2, Validation Loss: 0.03788269617978264\n",
      "Metrics {'MAE': 0.15334317, 'RMSE': 0.19463478, 'MAPE': 56.38602, 'SMAPE': 57.33444}\n",
      "Epoch 3, Train Loss: 0.01287332192106265\n",
      "Epoch 3, Validation Loss: 0.028092774836456075\n",
      "Metrics {'MAE': 0.13102953, 'RMSE': 0.16760899, 'MAPE': 48.55707, 'SMAPE': 51.174007}\n",
      "Epoch 4, Train Loss: 0.010112493331973435\n",
      "Epoch 4, Validation Loss: 0.022126466076930657\n",
      "Metrics {'MAE': 0.1154497, 'RMSE': 0.14874968, 'MAPE': 44.11081, 'SMAPE': 47.007523}\n",
      "Epoch 5, Train Loss: 0.008520992164391073\n",
      "Epoch 5, Validation Loss: 0.018624815213329652\n",
      "Metrics {'MAE': 0.104897894, 'RMSE': 0.13647276, 'MAPE': 41.540565, 'SMAPE': 44.043903}\n",
      "Epoch 6, Train Loss: 0.007612456767803309\n",
      "Epoch 6, Validation Loss: 0.016549682094003346\n",
      "Metrics {'MAE': 0.0986412, 'RMSE': 0.12864557, 'MAPE': 40.262085, 'SMAPE': 42.146843}\n",
      "Epoch 7, Train Loss: 0.007067169603175015\n",
      "Epoch 7, Validation Loss: 0.01523803815464763\n",
      "Metrics {'MAE': 0.09479043, 'RMSE': 0.12344245, 'MAPE': 39.68779, 'SMAPE': 40.966324}\n",
      "Epoch 8, Train Loss: 0.006701771840321045\n",
      "Epoch 8, Validation Loss: 0.014317597961053252\n",
      "Metrics {'MAE': 0.09207051, 'RMSE': 0.11965617, 'MAPE': 39.35656, 'SMAPE': 40.17414}\n",
      "Epoch 9, Train Loss: 0.00642341425013233\n",
      "Epoch 9, Validation Loss: 0.013600893825402154\n",
      "Metrics {'MAE': 0.08985065, 'RMSE': 0.116622865, 'MAPE': 38.94912, 'SMAPE': 39.513153}\n",
      "Epoch 10, Train Loss: 0.006190127179981044\n",
      "Epoch 10, Validation Loss: 0.013001087128513437\n",
      "Metrics {'MAE': 0.08776533, 'RMSE': 0.11402231, 'MAPE': 38.321198, 'SMAPE': 38.825302}\n",
      "Epoch 11, Train Loss: 0.005984630177073273\n",
      "Epoch 11, Validation Loss: 0.012479501112145098\n",
      "Metrics {'MAE': 0.08583141, 'RMSE': 0.11171169, 'MAPE': 37.548798, 'SMAPE': 38.127003}\n",
      "Epoch 12, Train Loss: 0.005800094650125342\n",
      "Epoch 12, Validation Loss: 0.012018219588379212\n",
      "Metrics {'MAE': 0.084022656, 'RMSE': 0.10962764, 'MAPE': 36.71793, 'SMAPE': 37.438267}\n",
      "Epoch 13, Train Loss: 0.005633553573948411\n",
      "Epoch 13, Validation Loss: 0.011607652612249641\n",
      "Metrics {'MAE': 0.08230308, 'RMSE': 0.107738815, 'MAPE': 35.89558, 'SMAPE': 36.77834}\n",
      "Epoch 14, Train Loss: 0.005483261374996129\n",
      "Epoch 14, Validation Loss: 0.011241460869581821\n",
      "Metrics {'MAE': 0.080755316, 'RMSE': 0.106025755, 'MAPE': 35.15006, 'SMAPE': 36.18867}\n",
      "Epoch 15, Train Loss: 0.005347781912473208\n",
      "Epoch 15, Validation Loss: 0.01091462857199504\n",
      "Metrics {'MAE': 0.079319105, 'RMSE': 0.10447311, 'MAPE': 34.492138, 'SMAPE': 35.667408}\n",
      "Epoch 16, Train Loss: 0.005225735201115607\n",
      "Epoch 16, Validation Loss: 0.010622769416145542\n",
      "Metrics {'MAE': 0.07797635, 'RMSE': 0.103066824, 'MAPE': 33.886345, 'SMAPE': 35.17491}\n",
      "Epoch 17, Train Loss: 0.005115759468155233\n",
      "Epoch 17, Validation Loss: 0.010361880721414791\n",
      "Metrics {'MAE': 0.076800264, 'RMSE': 0.10179332, 'MAPE': 33.337418, 'SMAPE': 34.71713}\n",
      "Epoch 18, Train Loss: 0.005016530595401117\n",
      "Epoch 18, Validation Loss: 0.010128262521260801\n",
      "Metrics {'MAE': 0.07570993, 'RMSE': 0.10063927, 'MAPE': 32.84598, 'SMAPE': 34.297615}\n",
      "Epoch 19, Train Loss: 0.004926792493111501\n",
      "Epoch 19, Validation Loss: 0.009918513598249239\n",
      "Metrics {'MAE': 0.07474328, 'RMSE': 0.09959173, 'MAPE': 32.426758, 'SMAPE': 33.9336}\n",
      "Epoch 20, Train Loss: 0.004845380509174792\n",
      "Epoch 20, Validation Loss: 0.009729535654461122\n",
      "Metrics {'MAE': 0.07387503, 'RMSE': 0.09863841, 'MAPE': 32.073147, 'SMAPE': 33.62146}\n",
      "Epoch 21, Train Loss: 0.004771239666581147\n",
      "Epoch 21, Validation Loss: 0.009558549575398074\n",
      "Metrics {'MAE': 0.07306105, 'RMSE': 0.09776784, 'MAPE': 31.761072, 'SMAPE': 33.339924}\n",
      "Epoch 22, Train Loss: 0.004703434427241557\n",
      "Epoch 22, Validation Loss: 0.009403104852775441\n",
      "Metrics {'MAE': 0.07230566, 'RMSE': 0.096969604, 'MAPE': 31.473848, 'SMAPE': 33.07518}\n",
      "Epoch 23, Train Loss: 0.0046411501650338504\n",
      "Epoch 23, Validation Loss: 0.009261078399825184\n",
      "Metrics {'MAE': 0.07163086, 'RMSE': 0.09623449, 'MAPE': 31.21232, 'SMAPE': 32.83046}\n",
      "Epoch 24, Train Loss: 0.00458369320336934\n",
      "Epoch 24, Validation Loss: 0.00913065715062925\n",
      "Metrics {'MAE': 0.07099206, 'RMSE': 0.09555448, 'MAPE': 30.971313, 'SMAPE': 32.602516}\n",
      "Epoch 25, Train Loss: 0.0045304826008946905\n",
      "Epoch 25, Validation Loss: 0.009010327514261007\n",
      "Metrics {'MAE': 0.07040715, 'RMSE': 0.094922744, 'MAPE': 30.755964, 'SMAPE': 32.397858}\n",
      "Epoch 26, Train Loss: 0.004481040804621314\n",
      "Epoch 26, Validation Loss: 0.008898843607098302\n",
      "Metrics {'MAE': 0.069863185, 'RMSE': 0.094333686, 'MAPE': 30.557365, 'SMAPE': 32.20866}\n",
      "Epoch 27, Train Loss: 0.004434981767099734\n",
      "Epoch 27, Validation Loss: 0.0087951937389067\n",
      "Metrics {'MAE': 0.06936181, 'RMSE': 0.09378269, 'MAPE': 30.373873, 'SMAPE': 32.03404}\n",
      "Epoch 28, Train Loss: 0.004391996479287318\n",
      "Epoch 28, Validation Loss: 0.00869857070638853\n",
      "Metrics {'MAE': 0.06888154, 'RMSE': 0.09326613, 'MAPE': 30.198748, 'SMAPE': 31.867748}\n",
      "Epoch 29, Train Loss: 0.004351840088181512\n",
      "Epoch 29, Validation Loss: 0.008608336844618487\n",
      "Metrics {'MAE': 0.06843754, 'RMSE': 0.09278113, 'MAPE': 30.033968, 'SMAPE': 31.712036}\n",
      "Epoch 30, Train Loss: 0.004314318785337807\n",
      "Epoch 30, Validation Loss: 0.0085239842575153\n",
      "Metrics {'MAE': 0.068017386, 'RMSE': 0.09232543, 'MAPE': 29.87941, 'SMAPE': 31.566902}\n",
      "Epoch 31, Train Loss: 0.004279277115948383\n",
      "Epoch 31, Validation Loss: 0.008445112175061642\n",
      "Metrics {'MAE': 0.06762599, 'RMSE': 0.091897294, 'MAPE': 29.737076, 'SMAPE': 31.434319}\n",
      "Epoch 32, Train Loss: 0.004246586654613914\n",
      "Epoch 32, Validation Loss: 0.008371394079671624\n",
      "Metrics {'MAE': 0.06726024, 'RMSE': 0.09149532, 'MAPE': 29.602068, 'SMAPE': 31.309258}\n",
      "Epoch 33, Train Loss: 0.004216139081366862\n",
      "Epoch 33, Validation Loss: 0.008302557932706001\n",
      "Metrics {'MAE': 0.06693854, 'RMSE': 0.09111837, 'MAPE': 29.486433, 'SMAPE': 31.203455}\n",
      "Epoch 34, Train Loss: 0.004187836668692308\n",
      "Epoch 34, Validation Loss: 0.008238369393545915\n",
      "Metrics {'MAE': 0.066633336, 'RMSE': 0.09076546, 'MAPE': 29.377348, 'SMAPE': 31.103739}\n",
      "Epoch 35, Train Loss: 0.0041615883690752555\n",
      "Epoch 35, Validation Loss: 0.008178610779235469\n",
      "Metrics {'MAE': 0.06634553, 'RMSE': 0.09043568, 'MAPE': 29.277514, 'SMAPE': 31.012589}\n",
      "Epoch 36, Train Loss: 0.004137305804399909\n",
      "Epoch 36, Validation Loss: 0.00812308197183644\n",
      "Metrics {'MAE': 0.06607813, 'RMSE': 0.090128146, 'MAPE': 29.188326, 'SMAPE': 30.931246}\n",
      "Epoch 37, Train Loss: 0.004114899746140676\n",
      "Epoch 37, Validation Loss: 0.008071579980691346\n",
      "Metrics {'MAE': 0.06582947, 'RMSE': 0.08984197, 'MAPE': 29.108044, 'SMAPE': 30.85786}\n",
      "Epoch 38, Train Loss: 0.004094279480702574\n",
      "Epoch 38, Validation Loss: 0.008023910210741794\n",
      "Metrics {'MAE': 0.0655929, 'RMSE': 0.08957628, 'MAPE': 29.033434, 'SMAPE': 30.789106}\n",
      "Epoch 39, Train Loss: 0.0040753519990033935\n",
      "Epoch 39, Validation Loss: 0.007979867918252507\n",
      "Metrics {'MAE': 0.06536748, 'RMSE': 0.08933011, 'MAPE': 28.96406, 'SMAPE': 30.724459}\n",
      "Epoch 40, Train Loss: 0.004058023403262049\n",
      "Epoch 40, Validation Loss: 0.007939256796175066\n",
      "Metrics {'MAE': 0.06515518, 'RMSE': 0.08910251, 'MAPE': 28.902462, 'SMAPE': 30.666464}\n",
      "Epoch 41, Train Loss: 0.004042197787533151\n",
      "Epoch 41, Validation Loss: 0.007901872022022657\n",
      "Metrics {'MAE': 0.06495721, 'RMSE': 0.088892475, 'MAPE': 28.845695, 'SMAPE': 30.612175}\n",
      "Epoch 42, Train Loss: 0.004027779020161817\n",
      "Epoch 42, Validation Loss: 0.007867513227906516\n",
      "Metrics {'MAE': 0.064772956, 'RMSE': 0.088699006, 'MAPE': 28.793404, 'SMAPE': 30.561268}\n",
      "Epoch 43, Train Loss: 0.004014671324983038\n",
      "Epoch 43, Validation Loss: 0.007835979460437289\n",
      "Metrics {'MAE': 0.06459933, 'RMSE': 0.08852106, 'MAPE': 28.744974, 'SMAPE': 30.513191}\n",
      "Epoch 44, Train Loss: 0.004002780043284726\n",
      "Epoch 44, Validation Loss: 0.0078070764087469265\n",
      "Metrics {'MAE': 0.06444516, 'RMSE': 0.08835766, 'MAPE': 28.70358, 'SMAPE': 30.471184}\n",
      "Epoch 45, Train Loss: 0.003992013848124152\n",
      "Epoch 45, Validation Loss: 0.007780615510829889\n",
      "Metrics {'MAE': 0.06430271, 'RMSE': 0.088207796, 'MAPE': 28.66621, 'SMAPE': 30.432333}\n",
      "Epoch 46, Train Loss: 0.003982283637143922\n",
      "Epoch 46, Validation Loss: 0.007756411662900492\n",
      "Metrics {'MAE': 0.06417674, 'RMSE': 0.0880705, 'MAPE': 28.634184, 'SMAPE': 30.398054}\n",
      "Epoch 47, Train Loss: 0.003973504187000902\n",
      "Epoch 47, Validation Loss: 0.007734291769071098\n",
      "Metrics {'MAE': 0.06406232, 'RMSE': 0.08794482, 'MAPE': 28.608248, 'SMAPE': 30.369162}\n",
      "Epoch 48, Train Loss: 0.003965594529393888\n",
      "Epoch 48, Validation Loss: 0.00771408630808925\n",
      "Metrics {'MAE': 0.063955545, 'RMSE': 0.087829866, 'MAPE': 28.585339, 'SMAPE': 30.342701}\n",
      "Epoch 49, Train Loss: 0.0039584785082678025\n",
      "Epoch 49, Validation Loss: 0.007695642436909325\n",
      "Metrics {'MAE': 0.06386182, 'RMSE': 0.087724805, 'MAPE': 28.567469, 'SMAPE': 30.320751}\n",
      "Epoch 50, Train Loss: 0.003952084568346494\n",
      "Epoch 50, Validation Loss: 0.007678809609976323\n",
      "Metrics {'MAE': 0.06377394, 'RMSE': 0.08762882, 'MAPE': 28.551147, 'SMAPE': 30.299906}\n",
      "Training complete, saving best and final model.\n",
      "Best model saved to WandB.\n",
      "Final model saved to WandB.\n",
      "Test Loss: 0.004893715493381023\n",
      "Test Metrics, {'MAE': 0.05253005, 'RMSE': 0.069955096, 'MAPE': 24.917423, 'SMAPE': 25.088228}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MAE</td><td>█▆▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>MAPE</td><td>█▆▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>RMSE</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>SMAPE</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MAE</td><td>0.06377</td></tr><tr><td>MAPE</td><td>28.55115</td></tr><tr><td>RMSE</td><td>0.08763</td></tr><tr><td>SMAPE</td><td>30.29991</td></tr><tr><td>test_loss</td><td>0.00489</td></tr><tr><td>train_loss</td><td>0.00395</td></tr><tr><td>val_loss</td><td>0.00768</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">RegressionTOY</strong> at: <a href='https://wandb.ai/aafvbd/toy_time_series/runs/ith7iwh9' target=\"_blank\">https://wandb.ai/aafvbd/toy_time_series/runs/ith7iwh9</a><br> View project at: <a href='https://wandb.ai/aafvbd/toy_time_series' target=\"_blank\">https://wandb.ai/aafvbd/toy_time_series</a><br>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>../wandb\\wandb\\run-20250308_043701-ith7iwh9\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    seed = 42\n",
    "    random.seed(42)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    config = get_config()\n",
    "    main(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:37:10.943933800Z",
     "start_time": "2025-03-08T09:37:00.920558100Z"
    }
   },
   "id": "23cd2a523251d4f0"
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [],
   "source": [
    "full_series = SunspotsDataset().load()\n",
    "train, val_test = full_series.split_after(0.80)\n",
    "val, test = val_test.split_after(0.50)\n",
    "scaler_transformer = Scaler()\n",
    "train_series = scaler_transformer.fit_transform(train)\n",
    "val_series = scaler_transformer.transform(val)\n",
    "test_series = scaler_transformer.transform(test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:49:39.399174300Z",
     "start_time": "2025-03-08T09:49:39.267454400Z"
    }
   },
   "id": "80645f6f47fc87b0"
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.series.Series"
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_series.pd_series().values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:53:00.037636500Z",
     "start_time": "2025-03-08T09:52:59.943253Z"
    }
   },
   "id": "e24edaef28e4d417"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "33c23154574b52a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
